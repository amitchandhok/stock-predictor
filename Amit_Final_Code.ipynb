{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q_/bgcxlv5x1n3723c2hpfljwl80000gn/T/ipykernel_8847/2384310978.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df_original.groupby('year', group_keys=False).apply(assign_category)\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "df_original = pd.read_excel(\"Ellis_Final_Data.xlsx\")\n",
    "\n",
    "# Convert 'date' to datetime format\n",
    "df_original['date'] = pd.to_datetime(df_original['date'])\n",
    "\n",
    "# Extract year for grouping\n",
    "df_original['year'] = df_original['date'].dt.year\n",
    "\n",
    "# Function to assign categories based on percentiles\n",
    "def assign_category(df):\n",
    "    top_thresh = df['Forward 3-Month Ret'].quantile(0.85)\n",
    "    bottom_thresh = df['Forward 3-Month Ret'].quantile(0.15)\n",
    "    \n",
    "    df['Rating'] = 'medium'\n",
    "    df.loc[df['Forward 3-Month Ret'] >= top_thresh, 'Rating'] = 'winner'\n",
    "    df.loc[df['Forward 3-Month Ret'] <= bottom_thresh, 'Rating'] = 'loser'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply function year-wise\n",
    "df = df_original.groupby('year', group_keys=False).apply(assign_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Rating' to numerical values (assuming 'winner', 'medium', 'loser' as categories)\n",
    "df['Rating'] = df['Rating'].map({'winner': 1, 'medium': 0, 'loser': -1})\n",
    "\n",
    "# Drop the 'Forward 3-Month Ret' columns\n",
    "df = df.drop(columns=['Forward 3-Month Ret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store model performance and feature importance\n",
    "model_performance = []\n",
    "feature_importance = {}\n",
    "\n",
    "# Drop 'date' and 'ticker' from features but keep them for filtering\n",
    "target = \"Rating\"\n",
    "\n",
    "# Collect all possible features before training\n",
    "all_features = set()\n",
    "\n",
    "# Prepare train data with windoews of 5 years and encode categorical variables\n",
    "for start_year in range(2003, 2019):  # Last start year: 2018\n",
    "    train_data = df[(df['date'].dt.year >= start_year) & (df['date'].dt.year <= start_year + 4) &\n",
    "                    (df['date'].dt.month >= 1) & (df['date'].dt.month <= 9)]\n",
    "    train_data = pd.get_dummies(train_data, columns=['Sector_name'], drop_first=True)\n",
    "    all_features.update(train_data.columns)\n",
    "\n",
    "# Remove target and identifier columns\n",
    "all_features -= {target, \"date\", \"TICKER\"}\n",
    "all_features = sorted(all_features)\n",
    "\n",
    "# Rolling window training and validation\n",
    "model_predictions = {}\n",
    "model_weights = {}\n",
    "\n",
    "# Run model for each window\n",
    "for start_year in range(2003, 2019):  # Last start year: 2018\n",
    "    train_start = f\"{start_year}-01\"\n",
    "    train_end = f\"{start_year + 4}-09\"\n",
    "    \n",
    "    val_dates = [\n",
    "        f\"{start_year + 4}-12\",\n",
    "        f\"{start_year + 5}-03\",\n",
    "        f\"{start_year + 5}-06\",\n",
    "        f\"{start_year + 5}-09\",\n",
    "    ]\n",
    "    \n",
    "    # Training data\n",
    "    train_data = df[(df['date'].dt.year >= start_year) & (df['date'].dt.year <= start_year + 4) &\n",
    "                    (df['date'].dt.month >= 1) & (df['date'].dt.month <= 9)]\n",
    "    train_data = pd.get_dummies(train_data, columns=['Sector_name'], drop_first=True)\n",
    "    train_data = train_data.reindex(columns=all_features, fill_value=0)\n",
    "    X_train = train_data\n",
    "    y_train = df.loc[train_data.index, target]\n",
    "    \n",
    "    # Train model\n",
    "    model = LogisticRegression(max_iter=1000, penalty='l1', solver='liblinear',class_weight='balanced',random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Store feature importance\n",
    "    feature_importance[f\"Train {train_start} - {train_end}\"] = {\n",
    "        feature: abs(coef) for feature, coef in zip(all_features, model.coef_.flatten())\n",
    "    }\n",
    "    \n",
    "    # Validate model\n",
    "    val_f1_scores = []\n",
    "    for val_date in val_dates:\n",
    "        val_data = df[df['date'].dt.strftime('%Y-%m') == val_date]\n",
    "        if not val_data.empty:\n",
    "            val_data = pd.get_dummies(val_data, columns=['Sector_name'], drop_first=True)\n",
    "            X_val = val_data.reindex(columns=all_features, fill_value=0)\n",
    "            y_val = df.loc[val_data.index, target]\n",
    "            if len(y_val.unique()) > 1:\n",
    "                preds = model.predict(X_val)\n",
    "                f1 = f1_score(y_val, preds, average='weighted')\n",
    "                val_f1_scores.append(f1)\n",
    "            else:\n",
    "                val_f1_scores.append(np.nan)\n",
    "        else:\n",
    "            val_f1_scores.append(np.nan)\n",
    "    \n",
    "    mean_f1 = np.nanmean(val_f1_scores) if len(val_f1_scores) > 0 else 0\n",
    "    model_performance.append({'Start Year': start_year, 'Validation F1 Scores': val_f1_scores, 'Mean F1': mean_f1})\n",
    "    model_weights[start_year] = mean_f1  # Store mean F1 for weighting\n",
    "    \n",
    "    # Predict December 2023\n",
    "    dec_2023_data = df[df['date'].dt.strftime('%Y-%m') == '2023-12']\n",
    "    if not dec_2023_data.empty:\n",
    "        dec_2023_data = pd.get_dummies(dec_2023_data, columns=['Sector_name'], drop_first=True)\n",
    "        X_dec_2023 = dec_2023_data.reindex(columns=all_features, fill_value=0)\n",
    "        model_predictions[start_year] = model.predict(X_dec_2023)\n",
    "\n",
    "# Normalize weights\n",
    "total_weight = sum(model_weights.values())\n",
    "normalized_weights = {year: (weight / total_weight) for year, weight in model_weights.items()} if total_weight > 0 else None\n",
    "\n",
    "# Compute weighted average predictions\n",
    "if normalized_weights:\n",
    "    weighted_preds = sum(\n",
    "        model_predictions[year] * normalized_weights[year] for year in model_predictions.keys()\n",
    "    )\n",
    "    final_dec_2023_preds = np.round(weighted_preds)  # Convert to class labels\n",
    "else:\n",
    "    final_dec_2023_preds = np.mean(list(model_predictions.values()), axis=0)\n",
    "    final_dec_2023_preds = np.round(final_dec_2023_preds)\n",
    "\n",
    "# Convert results to DataFrames\n",
    "performance_df = pd.DataFrame(model_performance)\n",
    "feature_importance_df = pd.DataFrame(feature_importance).fillna(0)\n",
    "\n",
    "dec_2023_results = pd.DataFrame({\n",
    "    'TICKER': df[df['date'].dt.strftime('%Y-%m') == '2023-12']['TICKER'],\n",
    "    'Predicted_Class': final_dec_2023_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MRO: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data found for MRO. Skipping...\n"
     ]
    }
   ],
   "source": [
    "# Extract data from yahoo finance for the predicted winners\n",
    "stocks = dec_2023_results[dec_2023_results[\"Predicted_Class\"] == 1]['TICKER']  # Select the 'TICKER' column\n",
    "returns_data = {}\n",
    "\n",
    "for stock in stocks:\n",
    "    try:\n",
    "        # Keep the original ticker for saving later\n",
    "        original_stock = stock\n",
    "        \n",
    "        # Replace GPS with GAP for fetching data\n",
    "        if stock == \"GPS\":\n",
    "            stock = \"GAP\"\n",
    "        \n",
    "        # Replace TUP with TUP.HM for fetching data\n",
    "        if stock == \"TUP\":\n",
    "            stock = \"TUP.HM\"\n",
    "\n",
    "        ticker = yf.Ticker(stock)\n",
    "        hist = ticker.history(start=\"2023-12-01\", end=\"2024-03-31\")\n",
    "        \n",
    "        if hist.empty:\n",
    "            print(f\"No data found for {stock}. Skipping...\")  # Debugging print\n",
    "            continue\n",
    "\n",
    "        # Filter dates\n",
    "        hist_dec = hist[(hist.index >= \"2023-12-01\") & (hist.index <= \"2023-12-31\")]\n",
    "        hist_mar = hist[(hist.index >= \"2024-03-01\") & (hist.index <= \"2024-03-31\")]\n",
    "\n",
    "        if hist_dec.empty or hist_mar.empty:\n",
    "            print(f\"Missing data for {stock} in December 2023 or March 2024. Skipping...\")  # Debugging print\n",
    "            continue\n",
    "\n",
    "        # Calculate average price\n",
    "        dec_2023_price = hist_dec['Close'].mean() if not hist_dec.empty else None\n",
    "        mar_2024_price = hist_mar['Close'].mean() if not hist_mar.empty else None\n",
    "\n",
    "        # Compute forward return\n",
    "        if dec_2023_price and mar_2024_price:\n",
    "            forward_return = (mar_2024_price - dec_2023_price) / dec_2023_price\n",
    "            returns_data[original_stock] = forward_return  # Save the original ticker\n",
    "        else:\n",
    "            print(f\"Data missing for {stock} in either December 2023 or March 2024. Skipping...\")  # Debugging print\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {stock}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "returns_df = pd.DataFrame(returns_data.items(), columns=['TICKER', 'Forward 3-Month Ret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from yahoo finance for the S&P500 market index\n",
    "try:\n",
    "    # Fetch the S&P 500 data\n",
    "    sp500 = yf.Ticker(\"^GSPC\")\n",
    "    sp500_hist = sp500.history(start=\"2023-12-01\", end=\"2024-03-31\")  # Define the date range\n",
    "\n",
    "    if not sp500_hist.empty:\n",
    "        # Filter the data for December 2023 and March 2024\n",
    "        sp500_dec = sp500_hist[(sp500_hist.index >= \"2023-12-01\") & (sp500_hist.index <= \"2023-12-31\")]\n",
    "        sp500_mar = sp500_hist[(sp500_hist.index >= \"2024-03-01\") & (sp500_hist.index <= \"2024-03-31\")]\n",
    "\n",
    "        # Calculate the average price for each period\n",
    "        sp500_dec_2023 = sp500_dec['Close'].mean() if not sp500_dec.empty else None\n",
    "        sp500_mar_2024 = sp500_mar['Close'].mean() if not sp500_mar.empty else None\n",
    "\n",
    "        # Compute forward return (if both prices are available)\n",
    "        if sp500_dec_2023 and sp500_mar_2024:\n",
    "            sp500_forward_return = (sp500_mar_2024 - sp500_dec_2023) / sp500_dec_2023\n",
    "        else:\n",
    "            sp500_forward_return = None\n",
    "    else:\n",
    "        sp500_forward_return = None\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching S&P 500 data: {e}\")\n",
    "    sp500_forward_return = None\n",
    "\n",
    "# Add S&P 500 return as a constant column to your DataFrame\n",
    "df[\"SP500 Forward 3-Month Ret\"] = sp500_forward_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output file name\n",
    "output_file = \"Ellis_Final_Output.xlsx\"\n",
    "\n",
    "# Filter the \"1\" class predicted stocks\n",
    "predicted_winners = dec_2023_results[dec_2023_results[\"Predicted_Class\"] == 1]\n",
    "\n",
    "# Randomly select up to 40 stocks\n",
    "random_winners = predicted_winners.sample(n=min(40, len(predicted_winners)), random_state=43)\n",
    "\n",
    "# Add the S&P 500 forward return to the random winners DataFrame\n",
    "random_winners[\"SP500 Forward 3-Month Ret\"] = sp500_forward_return  # Add the constant S&P 500 return to each row\n",
    "\n",
    "# Merge the returns_df with the random_winners based on TICKER\n",
    "random_winners_with_returns = random_winners.merge(returns_df, on=\"TICKER\", how=\"left\")\n",
    "\n",
    "# Create an Excel writer with multiple sheets\n",
    "with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "    # Save Predictions to the first sheet\n",
    "    dec_2023_results[[\"TICKER\", \"Predicted_Class\"]].to_excel(writer, sheet_name=\"Predictions\", index=False)\n",
    "    \n",
    "    # Save Feature Importance to the second sheet\n",
    "    feature_importance_df.to_excel(writer, sheet_name=\"Feature Importance\")\n",
    "\n",
    "    # Save Random 1-Class Stocks to the third sheet, now including 'Forward 3-Month Ret'\n",
    "    random_winners_with_returns[[\"TICKER\", \"Predicted_Class\", \"SP500 Forward 3-Month Ret\", \"Forward 3-Month Ret\"]].to_excel(writer, sheet_name=\"Final Portfolio\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
